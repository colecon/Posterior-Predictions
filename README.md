# Posterior-Predictions
AI learning algorithm for candy in a bag

Consider a simple example. Our favorite Surprise candy comes in two flavors: cherry
(yum) and lime (ugh). The manufacturer has a peculiar sense of humor and wraps each piece
of candy in the same opaque wrapper, regardless of flavor. The candy is sold in very large
bags, of which there are known to be five kindsâ€”again, indistinguishable from the outside:
h1: 100% cherry,
h2: 75% cherry + 25% lime,
h3: 50% cherry + 50% lime,
h4: 25% cherry + 75% lime,
h5: 100% lime

Write code to generate a data set of length 100 and plot the corresponding graphs for the predictions of which bag of candy you are picking from. 

Predict the outcome by using Bayes Rule and the Posterior Probabability formula.
Posterior probability = prior probability + new evidence (called likelihood)
P(hi|d1,...,dN) and P(DN+1=lime|d1,...,dN). 

*The Attached PDF is from a major Project. Refer only to question 2a.
